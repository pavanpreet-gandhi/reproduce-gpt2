{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2 import GPT, GPTConfig # our GPT class\n",
    "import time\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding('gpt2')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # dynamic device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13) # for reproducibility\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderLite:\n",
    "\n",
    "    def __init__(self, B, T):\n",
    "\n",
    "        self.B, self.T = B, T\n",
    "\n",
    "        with open('data/input.txt', 'r') as file:\n",
    "            text = file.read().replace('\\n', '')\n",
    "        \n",
    "        enc = tiktoken.get_encoding('gpt2')\n",
    "        tokens = enc.encode(text)\n",
    "        self.tokens = torch.tensor(tokens, dtype=torch.long, device=device)\n",
    "\n",
    "        self.current_batch = 0\n",
    "        self.number_of_batches = len(self.tokens) // (B * T)\n",
    "\n",
    "        print(f'Loaded {len(self.tokens)} tokens, {self.number_of_batches} batches of size {B}x{T}')\n",
    "\n",
    "    \n",
    "    def next_batch(self):\n",
    "\n",
    "        B, T = self.B, self.T\n",
    "\n",
    "        buf = self.tokens[self.current_batch * B * T : (self.current_batch + 1) * B * T + 1]\n",
    "        x = buf[:-1].view(B, T)\n",
    "        y = buf[1:].view(B, T)\n",
    "\n",
    "        self.current_batch += 1\n",
    "        if self.current_batch >= self.number_of_batches:\n",
    "            self.current_batch = 0\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(GPTConfig).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 297884 tokens, 145 batches of size 2x1024\n",
      "Step 0 | Loss 11.0395 | 552.2 ms | 3708.59 tok/s\n",
      "Step 1 | Loss 10.1234 | 373.6 ms | 5481.76 tok/s\n",
      "Step 2 | Loss 9.5636 | 375.3 ms | 5456.97 tok/s\n",
      "Step 3 | Loss 9.3886 | 371.6 ms | 5510.60 tok/s\n",
      "Step 4 | Loss 9.1647 | 372.4 ms | 5500.17 tok/s\n",
      "Step 5 | Loss 8.8967 | 371.7 ms | 5510.55 tok/s\n",
      "Step 6 | Loss 8.7383 | 373.3 ms | 5486.83 tok/s\n",
      "Step 7 | Loss 8.3745 | 373.0 ms | 5491.34 tok/s\n",
      "Step 8 | Loss 8.2043 | 372.8 ms | 5493.51 tok/s\n",
      "Step 9 | Loss 7.9448 | 373.3 ms | 5485.48 tok/s\n",
      "Step 10 | Loss 7.6409 | 374.6 ms | 5467.39 tok/s\n",
      "Step 11 | Loss 7.5783 | 373.7 ms | 5480.69 tok/s\n",
      "Step 12 | Loss 7.4408 | 374.1 ms | 5474.25 tok/s\n",
      "Step 13 | Loss 7.3493 | 374.7 ms | 5465.77 tok/s\n",
      "Step 14 | Loss 7.4255 | 373.7 ms | 5480.61 tok/s\n",
      "Step 15 | Loss 7.0674 | 378.8 ms | 5406.97 tok/s\n",
      "Step 16 | Loss 6.8323 | 375.3 ms | 5457.26 tok/s\n",
      "Step 17 | Loss 7.0912 | 376.0 ms | 5447.38 tok/s\n",
      "Step 18 | Loss 7.0000 | 373.8 ms | 5479.19 tok/s\n",
      "Step 19 | Loss 7.0514 | 375.8 ms | 5449.50 tok/s\n",
      "Step 20 | Loss 7.5785 | 375.0 ms | 5462.06 tok/s\n",
      "Step 21 | Loss 7.8825 | 375.0 ms | 5460.83 tok/s\n",
      "Step 22 | Loss 7.5902 | 374.5 ms | 5468.12 tok/s\n",
      "Step 23 | Loss 7.5807 | 375.5 ms | 5454.55 tok/s\n",
      "Step 24 | Loss 7.5125 | 374.9 ms | 5462.98 tok/s\n"
     ]
    }
   ],
   "source": [
    "B, T = 2, 1024\n",
    "data_loader = DataLoaderLite(B, T)\n",
    "\n",
    "model.train();\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "for i in range(25):\n",
    "    t0 = time.time()\n",
    "    x, y = data_loader.next_batch()\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = model(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    torch.cuda.synchronize() # wait for GPU to finish work\n",
    "    t1 = time.time()\n",
    "    dt = (t1 - t0) * 1000 # time difference in milliseconds\n",
    "    thoughput = (B * T) / (t1 - t0) # tokens per second\n",
    "    print(f\"Step {i} | Loss {loss.item():.4f} | {dt:.1f} ms | {thoughput:.2f} tok/s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
